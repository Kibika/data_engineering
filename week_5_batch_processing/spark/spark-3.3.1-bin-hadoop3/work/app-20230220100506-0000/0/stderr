Spark Executor Command: "/home/stl/spark/jdk-11.0.2/bin/java" "-cp" "/home/stl/spark/spark-3.3.1-bin-hadoop3/conf/:/home/stl/spark/spark-3.3.1-bin-hadoop3/jars/*" "-Xmx1024M" "-Dspark.driver.port=42781" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@de-zoomcamp.europe-west1-b.c.second-chariot-375510.internal:42781" "--executor-id" "0" "--hostname" "10.132.0.3" "--cores" "4" "--app-id" "app-20230220100506-0000" "--worker-url" "spark://Worker@10.132.0.3:33773"
========================================

Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
