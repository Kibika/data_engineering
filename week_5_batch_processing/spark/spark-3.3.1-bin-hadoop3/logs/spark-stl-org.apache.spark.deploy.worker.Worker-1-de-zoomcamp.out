Spark Command: /home/stl/spark/jdk-11.0.2/bin/java -cp /home/stl/spark/spark-3.3.1-bin-hadoop3/conf/:/home/stl/spark/spark-3.3.1-bin-hadoop3/jars/* -Xmx1g org.apache.spark.deploy.worker.Worker --webui-port 8081 spark://de-zoomcamp.europe-west1-b.c.second-chariot-375510.internal:7077
========================================
Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
23/02/20 09:58:09 INFO Worker: Started daemon with process name: 2398@de-zoomcamp
23/02/20 09:58:09 INFO SignalUtils: Registering signal handler for TERM
23/02/20 09:58:09 INFO SignalUtils: Registering signal handler for HUP
23/02/20 09:58:09 INFO SignalUtils: Registering signal handler for INT
23/02/20 09:58:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/02/20 09:58:10 INFO SecurityManager: Changing view acls to: stl
23/02/20 09:58:10 INFO SecurityManager: Changing modify acls to: stl
23/02/20 09:58:10 INFO SecurityManager: Changing view acls groups to: 
23/02/20 09:58:10 INFO SecurityManager: Changing modify acls groups to: 
23/02/20 09:58:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(stl); groups with view permissions: Set(); users  with modify permissions: Set(stl); groups with modify permissions: Set()
23/02/20 09:58:10 INFO Utils: Successfully started service 'sparkWorker' on port 33773.
23/02/20 09:58:10 INFO Worker: Worker decommissioning not enabled.
23/02/20 09:58:11 INFO Worker: Starting Spark worker 10.132.0.3:33773 with 4 cores, 14.6 GiB RAM
23/02/20 09:58:11 INFO Worker: Running Spark version 3.3.1
23/02/20 09:58:11 INFO Worker: Spark home: /home/stl/spark/spark-3.3.1-bin-hadoop3
23/02/20 09:58:11 INFO ResourceUtils: ==============================================================
23/02/20 09:58:11 INFO ResourceUtils: No custom resources configured for spark.worker.
23/02/20 09:58:11 INFO ResourceUtils: ==============================================================
23/02/20 09:58:11 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
23/02/20 09:58:11 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://de-zoomcamp.europe-west1-b.c.second-chariot-375510.internal:8081
23/02/20 09:58:11 INFO Worker: Connecting to master de-zoomcamp.europe-west1-b.c.second-chariot-375510.internal:7077...
23/02/20 09:58:11 INFO TransportClientFactory: Successfully created connection to de-zoomcamp.europe-west1-b.c.second-chariot-375510.internal/10.132.0.3:7077 after 54 ms (0 ms spent in bootstraps)
23/02/20 09:58:11 INFO Worker: Successfully registered with master spark://de-zoomcamp.europe-west1-b.c.second-chariot-375510.internal:7077
23/02/20 10:05:06 INFO Worker: Asked to launch executor app-20230220100506-0000/0 for test
23/02/20 10:05:06 INFO SecurityManager: Changing view acls to: stl
23/02/20 10:05:06 INFO SecurityManager: Changing modify acls to: stl
23/02/20 10:05:06 INFO SecurityManager: Changing view acls groups to: 
23/02/20 10:05:06 INFO SecurityManager: Changing modify acls groups to: 
23/02/20 10:05:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(stl); groups with view permissions: Set(); users  with modify permissions: Set(stl); groups with modify permissions: Set()
23/02/20 10:05:07 INFO ExecutorRunner: Launch command: "/home/stl/spark/jdk-11.0.2/bin/java" "-cp" "/home/stl/spark/spark-3.3.1-bin-hadoop3/conf/:/home/stl/spark/spark-3.3.1-bin-hadoop3/jars/*" "-Xmx1024M" "-Dspark.driver.port=42781" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@de-zoomcamp.europe-west1-b.c.second-chariot-375510.internal:42781" "--executor-id" "0" "--hostname" "10.132.0.3" "--cores" "4" "--app-id" "app-20230220100506-0000" "--worker-url" "spark://Worker@10.132.0.3:33773"
23/02/20 10:05:45 INFO Worker: Asked to kill executor app-20230220100506-0000/0
23/02/20 10:05:45 INFO ExecutorRunner: Runner thread for executor app-20230220100506-0000/0 interrupted
23/02/20 10:05:45 INFO ExecutorRunner: Killing process!
23/02/20 10:05:45 INFO Worker: Executor app-20230220100506-0000/0 finished with state KILLED exitStatus 143
23/02/20 10:05:45 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
23/02/20 10:05:45 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20230220100506-0000, execId=0)
23/02/20 10:05:45 INFO ExternalShuffleBlockResolver: Application app-20230220100506-0000 removed, cleanupLocalDirs = true
23/02/20 10:05:45 INFO Worker: Cleaning up local directories for application app-20230220100506-0000
23/02/20 10:27:03 ERROR Worker: RECEIVED SIGNAL TERM
23/02/20 10:27:03 INFO ShutdownHookManager: Shutdown hook called
23/02/20 10:27:03 INFO ShutdownHookManager: Deleting directory /tmp/spark-3cfc8120-2bf2-45cd-abe4-a1ff8e0f9825
